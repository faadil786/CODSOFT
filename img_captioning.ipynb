{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOcDLB0LzfEzsUaJp5D0taZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8EupSimPAHqj","executionInfo":{"status":"ok","timestamp":1719664925814,"user_tz":-330,"elapsed":19085,"user":{"displayName":"FAADIL SHAIKH","userId":"04649447713736110888"}},"outputId":"f131d343-1cb4-4927-a795-584b5e8c8f23"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n","import torch\n","from PIL import Image"],"metadata":{"id":"_J2FDW5dSZ1K","executionInfo":{"status":"ok","timestamp":1719665228930,"user_tz":-330,"elapsed":536,"user":{"displayName":"FAADIL SHAIKH","userId":"04649447713736110888"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","\n","\n","max_length = 16\n","num_beams = 4\n","gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n","def predict_step(image_paths):\n","  images = []\n","  for image_path in image_paths:\n","    i_image = Image.open(image_path)\n","    if i_image.mode != \"RGB\":\n","      i_image = i_image.convert(mode=\"RGB\")\n","\n","    images.append(i_image)\n","\n","  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n","  pixel_values = pixel_values.to(device)\n","\n","  output_ids = model.generate(pixel_values, **gen_kwargs)\n","\n","  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n","  preds = [pred.strip() for pred in preds]\n","  return preds"],"metadata":{"id":"c83NJ4MESabr","executionInfo":{"status":"ok","timestamp":1719665240395,"user_tz":-330,"elapsed":8878,"user":{"displayName":"FAADIL SHAIKH","userId":"04649447713736110888"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["predict_step(['sample-img.jpg'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08Kvoy6ySu_J","executionInfo":{"status":"ok","timestamp":1719665264106,"user_tz":-330,"elapsed":9307,"user":{"displayName":"FAADIL SHAIKH","userId":"04649447713736110888"}},"outputId":"8ca44516-4533-40ff-e2f9-68c0e96efe2b"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a man riding a horse on top of a beach']"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["predict_step(['sample-imgg.jpg'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OvYur4rgS2xX","executionInfo":{"status":"ok","timestamp":1719665282498,"user_tz":-330,"elapsed":10260,"user":{"displayName":"FAADIL SHAIKH","userId":"04649447713736110888"}},"outputId":"81dc872d-d27a-4850-9328-03d48203e169"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a red truck parked in the middle of a forest']"]},"metadata":{},"execution_count":15}]}]}